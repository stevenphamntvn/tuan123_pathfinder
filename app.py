# file: app.py
# Phi√™n b·∫£n ho√†n ch·ªânh: C·∫≠p nh·∫≠t vai tr√≤ m·ªõi cho Tu·∫•n 123 Pathfinder.

# --- PH·∫¶N S·ª¨A L·ªñI QUAN TR·ªåNG CHO STREAMLIT CLOUD ---
# Ba d√≤ng n√†y ph·∫£i n·∫±m ·ªü ngay ƒë·∫ßu file
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ----------------------------------------------------

import streamlit as st
import chromadb
import google.generativeai as genai
import os
import requests
import zipfile
from io import BytesIO
import time

# --- PH·∫¶N C·∫§U H√åNH ---
st.set_page_config(
    page_title="Pathfinder - Tr·ª£ l√Ω Tu·∫•n 123",
    page_icon="ü§ñ",
    layout="wide"
)

# S·ª≠ d·ª•ng st.secrets ƒë·ªÉ b·∫£o m·∫≠t API key khi tri·ªÉn khai online
try:
    # L·∫•y key t·ª´ Streamlit secrets (cho m√¥i tr∆∞·ªùng online)
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except (FileNotFoundError, KeyError):
    # D√πng cho local dev n·∫øu kh√¥ng c√≥ file secrets.toml
    # !!! THAY TH·∫æ B·∫∞NG API KEY C·ª¶A B·∫†N ƒê·ªÇ CH·∫†Y LOCAL
    GOOGLE_API_KEY = 'YOUR_GOOGLE_API_KEY_HERE'

# --- C·∫§U H√åNH TRI·ªÇN KHAI ONLINE ---
# !!! QUAN TR·ªåNG: D√°n ƒë∆∞·ªùng d·∫´n t·∫£i tr·ª±c ti·∫øp file zip c·ªßa b·∫°n v√†o ƒë√¢y
DB_ZIP_URL = "https://drive.google.com/uc?export=download&id=1WpTztD-D21zN5fyXxtS7QPz5kFxJ9AIG"
DB_PATH = 'chroma_db'
COLLECTION_NAME = 'tuan123_collection'

# --- B·∫¢NG GI√Å V√Ä L·ª∞A CH·ªåN M√î H√åNH ---
USD_TO_VND_RATE = 25500
MODEL_PRICING = {
    "gemini-1.5-pro-latest": {"input": 3.50, "output": 10.50},
    "gemini-1.5-flash-latest": {"input": 0.35, "output": 1.05}
}

# --- KH·ªûI T·∫†O AI V√Ä DATABASE ---

@st.cache_resource
def setup_database():
    """T·∫£i v√† gi·∫£i n√©n CSDL t·ª´ URL n·∫øu ch∆∞a c√≥."""
    if not os.path.exists(DB_PATH):
        st.info(f"Kh√¥ng t√¨m th·∫•y CSDL t·∫°i '{DB_PATH}'. B·∫Øt ƒë·∫ßu t·∫£i t·ª´ Google Drive...")
        try:
            r = requests.get(DB_ZIP_URL, stream=True)
            if r.status_code == 200:
                with st.spinner("ƒêang t·∫£i file chroma_db.zip..."):
                    zip_file = BytesIO(r.content)
                with st.spinner("ƒêang gi·∫£i n√©n CSDL..."):
                    with zipfile.ZipFile(zip_file, 'r') as z:
                        z.extractall('.')
                st.success("T·∫£i v√† gi·∫£i n√©n CSDL th√†nh c√¥ng!")
                # Ch·ªù m·ªôt ch√∫t ƒë·ªÉ h·ªá th·ªëng file ·ªïn ƒë·ªãnh
                time.sleep(2)
            else:
                st.error(f"L·ªói t·∫£i file: Status code {r.status_code}. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n URL.")
                return None, None
        except Exception as e:
            st.error(f"L·ªói trong qu√° tr√¨nh t·∫£i ho·∫∑c gi·∫£i n√©n: {e}")
            return None, None
    
    try:
        with st.spinner("ƒêang k·∫øt n·ªëi t·ªõi c∆° s·ªü d·ªØ li·ªáu vector..."):
            client = chromadb.PersistentClient(path=DB_PATH)
            collection = client.get_collection(name=COLLECTION_NAME)
        st.success("K·∫øt n·ªëi CSDL th√†nh c√¥ng!")
        return client, collection
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi t·ªõi ChromaDB t·∫°i '{DB_PATH}': {e}")
        st.error("H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ ch·∫°y c√°c script x·ª≠ l√Ω v√† l·∫≠p ch·ªâ m·ª•c d·ªØ li·ªáu tr∆∞·ªõc ƒë√≥.")
        return None, None

def configure_ai():
    """C·∫•u h√¨nh API key cho Google AI."""
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
    except Exception as e:
        st.error(f"L·ªói c·∫•u h√¨nh Google Generative AI: {e}")

# --- C√ÅC H√ÄM X·ª¨ L√ù L√ïI ---

def get_relevant_context(query, collection, n_results=5):
    """T√¨m c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan nh·∫•t trong CSDL."""
    if collection is None:
        return []
    results = collection.query(
        query_texts=[query],
        n_results=n_results
    )
    return results['documents'][0] if results['documents'] else []

def get_ai_response(query, model_name, collection, system_instruction):
    """T·∫°o c√¢u tr·∫£ l·ªùi t·ª´ AI d·ª±a tr√™n c√¢u h·ªèi v√† ng·ªØ c·∫£nh."""
    relevant_docs = get_relevant_context(query, collection)
    
    context_str = "\n---\n".join(relevant_docs)
    
    prompt = f"""{system_instruction}

D·ª±a v√†o c√°c th√¥ng tin, quy ƒë·ªãnh, v√† ki·∫øn th·ª©c ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.

---
{context_str}
---

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {query}
"""
    
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        
        # L·∫•y th√¥ng tin s·ª≠ d·ª•ng token
        usage_info = None
        if response.usage_metadata:
            usage = response.usage_metadata
            pricing = MODEL_PRICING[model_name]
            input_cost_usd = (usage.prompt_token_count / 1_000_000) * pricing["input"]
            output_cost_usd = (usage.candidates_token_count / 1_000_000) * pricing["output"]
            total_cost_usd = input_cost_usd + output_cost_usd
            total_cost_vnd = total_cost_usd * USD_TO_VND_RATE
            
            usage_info = {
                "prompt_tokens": usage.prompt_token_count,
                "response_tokens": usage.candidates_token_count,
                "total_tokens": usage.total_token_count,
                "cost_usd": total_cost_usd,
                "cost_vnd": total_cost_vnd,
                "model": model_name
            }
        
        return response.text, usage_info

    except Exception as e:
        return f"ƒê√£ c√≥ l·ªói x·∫£y ra khi g·ªçi API c·ªßa Google: {e}", None

# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (UI) ---

# Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn
configure_ai()
client, collection = setup_database()

# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title(" Pathfinder - Tr·ª£ l√Ω AI Tu·∫•n 123 ü§ñ")
st.caption("Tr·ª£ l√Ω ƒë∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n kho tri th·ª©c n·ªôi b·ªô c·ªßa c√¥ng ty.")

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat v√† chi ph√≠
if "messages" not in st.session_state:
    st.session_state.messages = []
if "total_session_cost_vnd" not in st.session_state:
    st.session_state.total_session_cost_vnd = 0.0

# C·∫•u h√¨nh sidebar
with st.sidebar:
    st.header("C√†i ƒë·∫∑t")
    
    model_name_map = {
        "Flash (Nhanh & R·∫ª)": "gemini-1.5-flash-latest",
        "Pro (M·∫°nh h∆°n)": "gemini-1.5-pro-latest"
    }
    selected_model_display = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh AI:",
        options=list(model_name_map.keys())
    )
    selected_model_name = model_name_map[selected_model_display]

    st.subheader("Vai tr√≤ c·ªßa AI")
    system_instruction = st.text_area(
        "B·∫°n mu·ªën AI ƒë√≥ng vai g√¨?",
        "B·∫°n l√† m·ªôt Tr·ª£ l√Ω AI am hi·ªÉu s√¢u s·∫Øc v·ªÅ c√°c quy tr√¨nh, quy ƒë·ªãnh v√† vƒÉn h√≥a c·ªßa c√¥ng ty b·∫•t ƒë·ªông s·∫£n Tu·∫•n 123. Nhi·ªám v·ª• c·ªßa b·∫°n l√† cung c·∫•p c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, chi ti·∫øt v√† chuy√™n nghi·ªáp cho c√°c nh√¢n vi√™n d·ª±a tr√™n kho tri th·ª©c ƒë∆∞·ª£c cung c·∫•p.",
        height=200
    )

    if st.button("X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán"):
        st.session_state.messages = []
        st.session_state.total_session_cost_vnd = 0.0
        st.rerun()

    st.divider()
    st.markdown(f"**T·ªïng chi ph√≠ phi√™n n√†y:**")
    st.markdown(f"### {st.session_state.total_session_cost_vnd:,.0f} VNƒê")


# Giao di·ªán chat ch√≠nh
if collection is not None:
    # Hi·ªÉn th·ªã c√°c tin nh·∫Øn ƒë√£ c√≥
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ quy tr√¨nh, nghi·ªáp v·ª•..."):
        # Th√™m c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # L·∫•y v√† hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi c·ªßa AI
        with st.chat_message("assistant"):
            with st.spinner(f"Pathfinder ({selected_model_display}) ƒëang suy nghƒ©..."):
                response_text, usage_info = get_ai_response(prompt, selected_model_name, collection, system_instruction)
                
                # T·∫°o response ƒë·∫ßy ƒë·ªß bao g·ªìm c·∫£ chi ti·∫øt s·ª≠ d·ª•ng API
                full_response_to_display = response_text
                if usage_info:
                    st.session_state.total_session_cost_vnd += usage_info['cost_vnd']
                    usage_html = f"""
                    <br>
                    <details style="font-size: 0.8em; color: grey;">
                        <summary>Chi ti·∫øt s·ª≠ d·ª•ng API</summary>
                        <p style="margin: 0; padding-left: 1em;">- Model: {usage_info['model']}<br>
                           - Chi ph√≠: {usage_info['cost_vnd']:,.0f} VNƒê<br>
                           - Tokens: {usage_info['total_tokens']}</p>
                    </details>
                    """
                    full_response_to_display += usage_html

                st.markdown(full_response_to_display, unsafe_allow_html=True)
        
        # L∆∞u c√¢u tr·∫£ l·ªùi (bao g·ªìm c·∫£ chi ti·∫øt) v√†o session state
        st.session_state.messages.append({"role": "assistant", "content": full_response_to_display})
        st.rerun()
else:
    st.warning("CSDL kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh v√† ƒë·∫£m b·∫£o ƒë√£ ch·∫°y c√°c b∆∞·ªõc chu·∫©n b·ªã d·ªØ li·ªáu.")
