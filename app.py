# file: app.py
# v2.3: Chuy·ªÉn sang d√πng Dropbox ƒë·ªÉ t·∫£i CSDL ·ªïn ƒë·ªãnh h∆°n

# --- PH·∫¶N S·ª¨A L·ªñI QUAN TR·ªåNG CHO STREAMLIT CLOUD ---
# Ba d√≤ng n√†y ph·∫£i n·∫±m ·ªü ngay ƒë·∫ßu file
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ----------------------------------------------------

import streamlit as st
import chromadb
import google.generativeai as genai
import os
import requests
import zipfile
from io import BytesIO
import time

# --- PH·∫¶N C·∫§U H√åNH ---
st.set_page_config(
    page_title="Pathfinder - Tr·ª£ l√Ω Tu·∫•n 123",
    page_icon="ü§ñ",
    layout="wide"
)

# S·ª≠ d·ª•ng st.secrets ƒë·ªÉ b·∫£o m·∫≠t API key khi tri·ªÉn khai online
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except (FileNotFoundError, KeyError):
    GOOGLE_API_KEY = 'AIzaSyBOAgpJI1voNNxeOC6sS7y01EJRXWSK0YU' # !!! D√ÅN API KEY C·ª¶A B·∫†N V√ÄO ƒê√ÇY

# --- C·∫§U H√åNH TRI·ªÇN KHAI ONLINE ---
# !!! THAY ƒê·ªîI: S·ª≠ d·ª•ng link t·∫£i tr·ª±c ti·∫øp t·ª´ Dropbox ---
DB_ZIP_URL = "https://www.dropbox.com/scl/fi/kzrz3y76uvhwlgdg9qhl7/chroma_db.zip?rlkey=h4bfzcx1opsts5vf34a4k23xm&st=ru7367m1&dl=1"

# --- T√™n CSDL v√† Collection ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a ---
DB_PATH = "chroma_db"
COLLECTION_NAME = "collection"

# --- B·∫¢NG GI√Å V√Ä L·ª∞A CH·ªåN M√î H√åNH ---
USD_TO_VND_RATE = 25500
MODEL_PRICING = {
    "gemini-1.5-pro-latest": {"input": 3.50, "output": 10.50},
    "gemini-1.5-flash-latest": {"input": 0.35, "output": 1.05}
}

# --- KH·ªûI T·∫†O AI V√Ä DATABASE ---

@st.cache_resource
def setup_database():
    """T·∫£i v√† gi·∫£i n√©n CSDL t·ª´ URL n·∫øu ch∆∞a c√≥. ƒê√£ c·∫≠p nh·∫≠t cho Dropbox."""
    if not os.path.exists(DB_PATH):
        st.info(f"Kh√¥ng t√¨m th·∫•y CSDL t·∫°i '{DB_PATH}'. B·∫Øt ƒë·∫ßu t·∫£i t·ª´ Dropbox...")
        
        try:
            # Logic t·∫£i tr·ª±c ti·∫øp t·ª´ Dropbox ƒë∆°n gi·∫£n h∆°n nhi·ªÅu
            response = requests.get(DB_ZIP_URL, stream=True)

            if response.status_code == 200:
                with st.spinner("ƒêang t·∫£i file CSDL... (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)"):
                    zip_file = BytesIO(response.content)
                with st.spinner("ƒêang gi·∫£i n√©n CSDL..."):
                    with zipfile.ZipFile(zip_file, 'r') as z:
                        z.extractall('.')
                st.success("T·∫£i v√† gi·∫£i n√©n CSDL th√†nh c√¥ng!")
                time.sleep(2)
            else:
                st.error(f"L·ªói t·∫£i file: Status code {response.status_code}. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n URL Dropbox.")
                return None, None

        except Exception as e:
            st.error(f"L·ªói trong qu√° tr√¨nh t·∫£i ho·∫∑c gi·∫£i n√©n: {e}")
            return None, None
    
    try:
        with st.spinner("ƒêang k·∫øt n·ªëi t·ªõi c∆° s·ªü d·ªØ li·ªáu vector..."):
            client = chromadb.PersistentClient(path=DB_PATH)
            collection = client.get_collection(name=COLLECTION_NAME)
        st.success("K·∫øt n·ªëi CSDL th√†nh c√¥ng!")
        return client, collection
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi t·ªõi ChromaDB t·∫°i '{DB_PATH}': {e}")
        return None, None

def configure_ai():
    """C·∫•u h√¨nh API key cho Google AI."""
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
    except Exception as e:
        st.error(f"L·ªói c·∫•u h√¨nh Google Generative AI: {e}")

# --- C√ÅC H√ÄM X·ª¨ L√ù L√ïI ---

def get_relevant_context(query, collection, n_results=5):
    if collection is None: return []
    results = collection.query(query_texts=[query], n_results=n_results)
    return results['documents'][0] if results['documents'] else []

def get_ai_response(query, model_name, collection, system_instruction):
    relevant_docs = get_relevant_context(query, collection)
    context_str = "\n---\n".join(relevant_docs)
    prompt = f"""{system_instruction}\n\nD·ª±a v√†o c√°c th√¥ng tin, quy ƒë·ªãnh, v√† ki·∫øn th·ª©c ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.\n\n---\n{context_str}\n---\n\nC√¢u h·ªèi: {query}"""
    
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        usage_info = None
        if response.usage_metadata:
            usage = response.usage_metadata
            pricing = MODEL_PRICING[model_name]
            total_cost_usd = ((usage.prompt_token_count / 1_000_000) * pricing["input"]) + ((usage.candidates_token_count / 1_000_000) * pricing["output"])
            usage_info = {
                "total_tokens": usage.total_token_count,
                "cost_vnd": total_cost_usd * USD_TO_VND_RATE,
                "model": model_name
            }
        return response.text, usage_info
    except Exception as e:
        return f"L·ªói khi g·ªçi API Google: {e}", None

# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (UI) ---

configure_ai()
client, collection = setup_database()

st.title(" Pathfinder - Tr·ª£ l√Ω AI Tu·∫•n 123 ü§ñ")
st.caption("Tr·ª£ l√Ω ƒë∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n kho tri th·ª©c n·ªôi b·ªô c·ªßa c√¥ng ty.")

if "messages" not in st.session_state: st.session_state.messages = []
if "total_session_cost_vnd" not in st.session_state: st.session_state.total_session_cost_vnd = 0.0

with st.sidebar:
    st.header("C√†i ƒë·∫∑t")
    model_name_map = {"Flash (Nhanh & R·∫ª)": "gemini-1.5-flash-latest", "Pro (M·∫°nh h∆°n)": "gemini-1.5-pro-latest"}
    selected_model_display = st.selectbox("Ch·ªçn m√¥ h√¨nh AI:", options=list(model_name_map.keys()))
    selected_model_name = model_name_map[selected_model_display]
    system_instruction = st.text_area("Vai tr√≤ c·ªßa AI:", "B·∫°n l√† m·ªôt Tr·ª£ l√Ω AI am hi·ªÉu s√¢u s·∫Øc v·ªÅ c√°c quy tr√¨nh, quy ƒë·ªãnh v√† vƒÉn h√≥a c·ªßa c√¥ng ty b·∫•t ƒë·ªông s·∫£n Tu·∫•n 123. Nhi·ªám v·ª• c·ªßa b·∫°n l√† cung c·∫•p c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, chi ti·∫øt v√† chuy√™n nghi·ªáp cho c√°c nh√¢n vi√™n d·ª±a tr√™n kho tri th·ª©c ƒë∆∞·ª£c cung c·∫•p.", height=200)
    if st.button("X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán"):
        st.session_state.messages = []
        st.session_state.total_session_cost_vnd = 0.0
        st.rerun()
    st.divider()
    st.markdown("**T·ªïng chi ph√≠ phi√™n n√†y:**")
    st.markdown(f"### {st.session_state.total_session_cost_vnd:,.0f} VNƒê")

if collection is not None:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ quy tr√¨nh, nghi·ªáp v·ª•..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner(f"Pathfinder ({selected_model_display}) ƒëang suy nghƒ©..."):
                response_text, usage_info = get_ai_response(prompt, selected_model_name, collection, system_instruction)
                full_response_to_display = response_text
                if usage_info:
                    st.session_state.total_session_cost_vnd += usage_info['cost_vnd']
                    usage_html = f"""<br><details style="font-size: 0.8em; color: grey;"><summary>Chi ti·∫øt</summary><p style="margin: 0; padding-left: 1em;">- Model: {usage_info['model']}<br>- Chi ph√≠: {usage_info['cost_vnd']:,.0f} VNƒê<br>- Tokens: {usage_info['total_tokens']}</p></details>"""
                    full_response_to_display += usage_html
                st.markdown(full_response_to_display, unsafe_allow_html=True)
        st.session_state.messages.append({"role": "assistant", "content": full_response_to_display})
        st.rerun()
else:
    st.warning("CSDL kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh.")
