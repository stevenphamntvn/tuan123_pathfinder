# file: app.py
# Phi√™n b·∫£n ho√†n ch·ªânh: Giao di·ªán tinh g·ªçn, hi·ªÉn th·ªã chi ph√≠ ·ªü g√≥c tr√°i.

# --- PH·∫¶N S·ª¨A L·ªñI QUAN TR·ªåNG CHO STREAMLIT CLOUD ---
# Ba d√≤ng n√†y ph·∫£i n·∫±m ·ªü ngay ƒë·∫ßu file
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ----------------------------------------------------

import streamlit as st
import chromadb
import google.generativeai as genai
import os
import requests
import zipfile
from io import BytesIO

# --- PH·∫¶N C·∫§U H√åNH ---
# API Key c·ªßa b·∫°n t·ª´ Google Cloud
GOOGLE_API_KEY = 'AIzaSyBOAgpJI1voNNxeOC6sS7y01EJRXWSK0YU' # !!! THAY API KEY C·ª¶A B·∫†N V√ÄO ƒê√ÇY !!!

# --- C·∫§U H√åNH TRI·ªÇN KHAI ONLINE ---
# !!! QUAN TR·ªåNG: D√°n ƒë∆∞·ªùng d·∫´n t·∫£i tr·ª±c ti·∫øp file zip c·ªßa b·∫°n v√†o ƒë√¢y
DB_ZIP_URL = "https://drive.google.com/uc?export=download&id=1WpTztD-D21zN5fyXxtS7QPz5kFxJ9AIG"
DB_PATH = 'chroma_db'
COLLECTION_NAME = 'collection'

# --- B·∫¢NG GI√Å V√Ä L·ª∞A CH·ªåN M√î H√åNH ---
MODEL_PRICING = {
    "gemini-1.5-flash-latest": {
        "input": 0.35,
        "output": 1.05
    },
    "gemini-1.5-pro-latest": {
        "input": 3.50,
        "output": 10.50
    }
}
MODEL_OPTIONS = list(MODEL_PRICING.keys())

# --- T·ª∂ GI√Å V√Ä C√ÅC VAI TR√í (PERSONA) CHO AI ---
USD_TO_VND_RATE = 25500  # T·ª∑ gi√° USD/VND (b·∫°n c√≥ th·ªÉ c·∫≠p nh·∫≠t)
PERSONAS = {
    "T∆∞·ªõng qu√¢n Ch·ªâ ƒë·∫°o": "B·∫°n l√† m·ªôt T∆∞·ªõng qu√¢n c·ªßa Tu·∫•n 123, ƒë∆∞a ra c√°c ch·ªâ d·∫´n, quy tr√¨nh m·ªôt c√°ch d·ª©t kho√°t, r√µ r√†ng v√† ƒë·∫ßy nƒÉng l∆∞·ª£ng.",
    "Chuy√™n gia ƒê√†o t·∫°o": "B·∫°n l√† m·ªôt chuy√™n gia ƒë√†o t·∫°o th√¢n thi·ªán, gi·∫£i th√≠ch c√°c t√¨nh hu·ªëng, k·ªπ nƒÉng cho chuy√™n vi√™n, chuy√™n gia m·ªôt c√°ch chi ti·∫øt, d·ªÖ hi·ªÉu, k√®m theo v√≠ d·ª• th·ª±c t·∫ø."
}
PERSONA_OPTIONS = list(PERSONAS.keys())


# --- H√ÄM T·∫¢I V√Ä GI·∫¢I N√âN DATABASE ---
def setup_database():
    """Ki·ªÉm tra, t·∫£i v·ªÅ v√† gi·∫£i n√©n database n·∫øu c·∫ßn."""
    if not os.path.exists(DB_PATH):
        st.info(f"Kh√¥ng t√¨m th·∫•y database '{DB_PATH}'. B·∫Øt ƒë·∫ßu t·∫£i v·ªÅ t·ª´ cloud...")
        st.warning("Qu√° tr√¨nh n√†y ch·ªâ di·ªÖn ra m·ªôt l·∫ßn v√† c√≥ th·ªÉ m·∫•t v√†i ph√∫t.")
        
        if not DB_ZIP_URL or DB_ZIP_URL == "YOUR_DIRECT_DOWNLOAD_LINK_TO_THE_DB_ZIP_FILE":
            st.error("L·ªói c·∫•u h√¨nh: Vui l√≤ng cung c·∫•p DB_ZIP_URL trong file app.py.")
            return False

        try:
            with st.spinner('ƒêang t·∫£i database...'):
                response = requests.get(DB_ZIP_URL)
                response.raise_for_status()
            with st.spinner('ƒêang gi·∫£i n√©n...'):
                with zipfile.ZipFile(BytesIO(response.content)) as z:
                    z.extractall('.')
            st.success("Thi·∫øt l·∫≠p database th√†nh c√¥ng! ƒêang t·∫£i l·∫°i...")
            st.rerun()
        except Exception as e:
            st.error(f"L·ªói khi t·∫£i ho·∫∑c gi·∫£i n√©n database: {e}")
            return False
    return True

# --- KH·ªûI T·∫†O DATABASE ---
@st.cache_resource
def load_db():
    """K·∫øt n·ªëi t·ªõi database v√† tr·∫£ v·ªÅ collection."""
    try:
        client = chromadb.PersistentClient(path=DB_PATH)
        collection = client.get_collection(name=COLLECTION_NAME)
        return collection
    except Exception as e:
        st.error(f"L·ªói k·∫øt n·ªëi database: {e}")
        return None

# --- H√ÄM LOGIC X·ª¨ L√ù C√ÇU H·ªéI ---
def get_ai_response(question, model, collection, model_name, system_instruction):
    """L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ AI v√† th√¥ng tin s·ª≠ d·ª•ng."""
    results = collection.query(query_texts=[question], n_results=3)
    context = "\n\n---\n\n".join(results['documents'][0])
    
    prompt = f"""{system_instruction}

    D·ª±a v√†o th√¥ng tin tham kh·∫£o ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
    
    Th√¥ng tin tham kh·∫£o: {context}
    
    C√¢u h·ªèi: {question}"""
    
    response = model.generate_content(prompt)
    usage_info = None
    try:
        usage = response.usage_metadata
        prompt_tokens = usage.prompt_token_count
        response_tokens = usage.candidates_token_count
        
        price_input = MODEL_PRICING[model_name]["input"]
        price_output = MODEL_PRICING[model_name]["output"]
        
        input_cost = (prompt_tokens / 1_000_000) * price_input
        output_cost = (response_tokens / 1_000_000) * price_output
        total_cost_usd = input_cost + output_cost
        
        usage_info = {
            "cost_vnd": total_cost_usd * USD_TO_VND_RATE
        }
    except Exception:
        pass

    return response.text, usage_info

# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG STREAMLIT ---
st.set_page_config(page_title="Pathfinder - Tr·ª£ l√Ω Tu·∫•n 123", page_icon="üåø")
st.title(" Pathfinder - Tr·ª£ l√Ω Tu·∫•n 123")

# Kh·ªüi t·∫°o t·ªïng chi ph√≠ trong session state
if 'total_session_cost_vnd' not in st.session_state:
    st.session_state.total_session_cost_vnd = 0.0

# Thanh b√™n ƒë·ªÉ ch·ªçn m√¥ h√¨nh v√† vai tr√≤
with st.sidebar:
    st.header("C·∫•u h√¨nh")
    selected_model_name = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh AI:",
        options=MODEL_OPTIONS,
        index=0,
    )
    
    selected_persona_name = st.selectbox(
        "Ch·ªçn phong c√°ch tr·∫£ l·ªùi:",
        options=PERSONA_OPTIONS,
        index=1 # M·∫∑c ƒë·ªãnh ch·ªçn "L∆∞∆°ng y tr·∫ª"
    )
    system_instruction = PERSONAS[selected_persona_name]
    

# B∆∞·ªõc 1: ƒê·∫£m b·∫£o database ƒë√£ s·∫µn s√†ng
if setup_database():
    # B∆∞·ªõc 2: Kh·ªüi t·∫°o AI v√† DB
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        llm_model = genai.GenerativeModel(selected_model_name)
        collection = load_db()
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o AI. Vui l√≤ng ki·ªÉm tra API Key. L·ªói: {e}")
        llm_model = None
        collection = None

    # B∆∞·ªõc 3: Hi·ªÉn th·ªã giao di·ªán chat
    if llm_model and collection:
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("V√≠ d·ª•: B·ªánh Th√°i D∆∞∆°ng l√† g√¨?"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner(f"AI ({selected_model_name}) ƒëang suy nghƒ©..."):
                    response_text, usage_info = get_ai_response(prompt, llm_model, collection, selected_model_name, system_instruction)
                    
                    # Ch·ªâ hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi, kh√¥ng hi·ªÉn th·ªã ngu·ªìn
                    st.markdown(response_text)
                    
                    if usage_info:
                        # C·∫≠p nh·∫≠t t·ªïng chi ph√≠
                        st.session_state.total_session_cost_vnd += usage_info['cost_vnd']
            
            # L∆∞u c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠ chat
            st.session_state.messages.append({"role": "assistant", "content": response_text})
            
            # Ch·∫°y l·∫°i ƒë·ªÉ c·∫≠p nh·∫≠t t·ªïng chi ph√≠
            st.rerun()

    # Hi·ªÉn th·ªã t·ªïng chi ph√≠ ·ªü g√≥c d∆∞·ªõi b√™n tr√°i
    # S·ª≠ d·ª•ng HTML v√† CSS ƒë·ªÉ ƒë·ªãnh v·ªã
    total_cost_display = f"""
    <div style="
        position: fixed;
        bottom: 10px;
        left: 10px; /* ƒê√£ ƒë·ªïi t·ª´ right sang left */
        background-color: #f0f2f6;
        padding: 5px 10px;
        border-radius: 5px;
        border: 1px solid #ddd;
        font-size: 0.8em;
        z-index: 1000;
        color: #333;
    ">
        API: {st.session_state.total_session_cost_vnd:,.0f} VNƒê
    </div>
    """
    st.markdown(total_cost_display, unsafe_allow_html=True)
